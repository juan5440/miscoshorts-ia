# Miscoshorts - Generador de Shorts con Inteligencia Artificial

Este proyecto automatiza la creaci√≥n de YouTube Shorts virales a partir de videos largos, utilizando Inteligencia Artificial para el an√°lisis de contenido, transcripci√≥n de audio y generaci√≥n de subt√≠tulos.

## üìã Descripci√≥n del Proyecto

**Miscoshorts** es una herramienta de escritorio que permite a los creadores de contenido:

1.  **Descargar** videos de YouTube o utilizar archivos locales.
2.  **Transcribir** el audio autom√°ticamente a texto.
3.  **Analizar** el contenido con IA (Google Gemini) para encontrar los segmentos con mayor potencial viral.
4.  **Generar** un video vertical (9:16) optimizado para Shorts/Reels/TikTok.
5.  **A√±adir subt√≠tulos** din√°micos y estilizados autom√°ticamente.

## üõ†Ô∏è Herramientas y Tecnolog√≠as Utilizadas

El proyecto combina varias tecnolog√≠as potentes:

- **Python 3.12+**: Lenguaje principal.
- **CustomTkinter**: Para la Interfaz Gr√°fica de Usuario (GUI) moderna y modo oscuro.
- **OpenAI Whisper**: Para la transcripci√≥n de audio de alta precisi√≥n.
- **Google Gemini (API)**: Como "cerebro" para analizar el texto, detectar momentos virales y sugerir t√≠tulos.
- **MoviePy**: Para la edici√≥n de video (recorte, redimensionado 9:16).
- **FFmpeg**: Motor de procesamiento de video y audio subyacente.
- **yt-dlp**: Para la descarga robusta de videos de YouTube.
- **Pillow (PIL)**: Para el procesamiento de gr√°ficos en los subt√≠tulos.

## ‚öôÔ∏è Requisitos Previos

Antes de instalar, aseg√∫rate de tener:


# DOCUMENTACI√ìN - Miscoshorts

Este documento recoge la descripci√≥n t√©cnica, las instrucciones de instalaci√≥n y el uso del proyecto "Miscoshorts" ‚Äîuna herramienta para generar YouTube Shorts autom√°ticos a partir de v√≠deos largos usando transcripci√≥n y an√°lisis por IA.

## 1. Resumen r√°pido

-+- Prop√≥sito: detectar el fragmento m√°s viral de un v√≠deo largo, recortarlo a formato vertical 9:16, a√±adir subt√≠tulos y generar un MP4 listo para publicar.
-+- Modo de uso: CLI (`maker.py`) o GUI (`gui_app.py` / `iniciar.bat`).

## 2. Requisitos

-+- Python 3.12+
-+- FFmpeg (binario en PATH o `ffmpeg.exe` en la carpeta del proyecto)
-+- Clave de API de Google Gemini (no subirla a repositorios p√∫blicos)
-+- Dependencias Python listadas en [requirements.txt](requirements.txt)

Instala dependencias:

```bash
pip install -r requirements.txt
```

## 3. Instalaci√≥n (Windows - pasos recomendados)

1. Clona el repositorio y sit√∫ate en la carpeta:

```bash
git clone <repo-url>
cd miscoshorts-ai
```

2. Crea un entorno virtual (opcional pero recomendado):

```bash
python -m venv .venv
.venv\Scripts\activate
```

3. Instala dependencias:

```bash
pip install -r requirements.txt
```

4. Instala o copia `ffmpeg.exe`:

- Si usas Windows, descarga FFmpeg y coloca `ffmpeg.exe` en la carpeta del proyecto o agrega FFmpeg al PATH.
- El script `maker.py` intenta copiar el binario proporcionado por `imageio-ffmpeg` a `ffmpeg.exe` en la carpeta del proyecto si no lo encuentra.

5. Configura la API Key de Gemini:

- Abre [cerebro_gemini.py](cerebro_gemini.py) y reemplaza `GEMINI_API_KEY` por tu clave.
- Alternativa m√°s segura: modificar el c√≥digo para leer la clave desde una variable de entorno y evitar hardcodearla.

Ejemplo (recomendado):

```python
import os
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
```

## 4. Uso

4.1 Desde la GUI

- Ejecuta `iniciar.bat` o `python gui_app.py` para abrir la interfaz.
- Pega la URL de YouTube o selecciona un archivo local.
- Pulsa "Analizar Video" para transcribir y pedir la selecci√≥n al modelo Gemini.
- Ajusta tiempos si quieres y pulsa "Generar Short".

4.2 Desde CLI (flujo principal)

- Edita `URL_VIDEO` en [maker.py](maker.py) o pasa un archivo local a la funci√≥n `descargar_video`.
- Ejecuta:

```bash
python maker.py
```

- Flujo que realiza `maker.py`:
  1. Descarga el v√≠deo (`yt-dlp`) o usa archivo local.
  2. Transcribe con `whisper` (modelo `base`).
  3. Env√≠a segmentos a `cerebro_gemini.encontrar_clip_viral()` para obtener t√≠tulo, inicio, fin y raz√≥n.
  4. El usuario confirma o ajusta tiempos.
  5. Se recorta el clip, se centra para formato vertical y se a√±aden subt√≠tulos (`subtitulos.py`).
  6. Genera `short_con_subs.mp4`.

## 5. Arquitectura y m√≥dulos (tareas principales)

- [maker.py](maker.py): Orquestador principal. Descarga, transcribe (Whisper), consulta a Gemini, y genera el clip final.
- [cerebro_gemini.py](cerebro_gemini.py): Encapsula la llamada al modelo generativo de Google Gemini y construye el prompt para elegir el clip viral.
- [subtitulos.py](subtitulos.py): Agrupa palabras en subt√≠tulos, formatea texto y compone el clip final con `MoviePy`.
- [gui_app.py](gui_app.py): Interfaz gr√°fica (CustomTkinter) ‚Äî atajos para cargar URL/archivo, analizar y generar.
- [verify_fix.py](verify_fix.py): Script auxiliar para comprobar/corregir el manejo de `ffmpeg.exe` en Windows.
- [verify_subs_standalone.py](verify_subs_standalone.py): Prueba local para comprobar el render de subt√≠tulos.
- [requirements.txt](requirements.txt): Dependencias Python.
- `ffmpeg.exe`: (opcional) se puede incluir en la carpeta para evitar problemas en Windows.

## 6. Detalle t√©cnico del flujo

1. Descarga y preparaci√≥n

- `yt-dlp` descarga el v√≠deo (si se proporciona URL).
- `imageio-ffmpeg` proporciona un binario que `maker.py` copia como `ffmpeg.exe` para compatibilidad con `whisper`.

2. Transcripci√≥n

- Se carga el modelo `whisper` con `whisper.load_model("base")` y se obtiene `resultado['segments']` que contienen palabras con timestamps.

3. An√°lisis por Gemini

- `cerebro_gemini.encontrar_clip_viral()` construye un prompt con la transcripci√≥n timestamped y genera una respuesta con formato:

  TITULO: ...
  INICIO: ...
  FIN: ...
  RAZON: ...

- `maker.parsear_respuesta_gemini()` extrae esos valores para su uso.

4. Render y subt√≠tulos

- `maker.crear_clip_final()` recorta y centra el frame para formato vertical.
- `subtitulos.generar_subtitulos()` agrupa palabras en bloques (por caracteres y duraci√≥n), crea `TextClip`s estilizados y los superpone con `CompositeVideoClip`.

## 7. Dependencias clave

- yt-dlp
- moviepy
- google-generativeai
- openai-whisper
- customtkinter
- imageio-ffmpeg

Instala todo con `pip install -r requirements.txt`.

## 8. Soluci√≥n de problemas

- Problema: `Whisper` no encuentra `ffmpeg` ‚Üí Aseg√∫rate de que `ffmpeg.exe` est√° en la carpeta del proyecto o que FFmpeg est√° en tu PATH.
- Problema: errores de fuente en `moviepy.TextClip` ‚Üí cambia la ruta de `font` en [subtitulos.py](subtitulos.py) a una fuente instalada (ej. `C:\Windows\Fonts\arial.ttf`).
- Problema: clave de Gemini incluida en el repo ‚Üí reemplaza uso hardcodeado por variable de entorno y regenera la clave si fue comprometida.

## 9. Seguridad y buenas pr√°cticas

- Nunca subir claves API a repositorios p√∫blicos. Usa variables de entorno (`GEMINI_API_KEY`) o un archivo `.env` (ignorarlo en `.gitignore`).
- Revisa y limita permisos y cuotas de la API de Gemini.

## 10. C√≥mo contribuir

1. Crea un fork.
2. A√±ade tests y documentaci√≥n para cambios grandes.
3. Abre un Pull Request explicando el cambio.

## 11. Recursos y referencias

- Tutorial en YouTube (si aplica) ‚Äî enlace en [README.md](README.md).
- Documentaci√≥n de `moviepy`, `yt-dlp`, `whisper` y `google-generativeai`.

---

Si quieres, puedo:
- actualizar tambi√©n el `README.md` con un resumen reducido, o
- convertir instrucciones de configuraci√≥n para usar variables de entorno en lugar de claves hardcodeadas.
